

load:
  dataset_name: ''

tokenizer_transformer:
  model_name_zip: 'ted_hrlr_translate_pt_en_converter.zip'
  model_name: 'ted_hrlr_translate/pt_to_en'
  BUFFER_SIZE: 20000
  BATCH_SIZE: 64
  MAX_TOKENS: 128

postional_encoding:
  input_vocab_size: 7765
  target_vocab_size: 7010
  d_model: 512

train_transformer:
  input_vocab_size: 8000
  target_vocab_size: 8000
  MAX_TOKENS: 128

  num_layers: 4
  d_model: 128
  dff: 512
  num_attention_heads: 8
  dropout_rate: 0.1 
  EPOCHS: 2 