load:
  dataset_name: 'mydata1'

tokenizer_transformer:
  model_name_zip: 'ted_hrlr_translate_pt_en_converter.zip'
  model_name: 'ted_hrlr_translate/pt_to_en'
  folder_name: 'ted_hrlr_translate_pt_en_converter'
  BUFFER_SIZE: 20000
  BATCH_SIZE: 64
  MAX_TOKENS: 128

positional_encoding:
  input_vocab_size: 7765
  target_vocab_size: 7010
  d_model: 512

train_transformer:
  num_layers_encoder: 4
  num_layers_decoder: 6
  d_model: 128
  dff: 512
  num_attention_heads_encoder: 6
  num_attention_heads_decoder: 8
  dropout_rate: 0.1 
  EPOCHS: 2 