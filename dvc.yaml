


stages:
  # LOADS THE DATASET. OUTPUT . Dataset Loaded
  load: #Stage name 
    cmd: python src/data/load_dataset.py data/ #The command that is going to be executed
    params: # from params.yml
    - model_name
    outs:
    - dataset

  tokenizer_transformer:
  # PREPARES TOKEN BATCHES .ALSO LOADS TOKENIZED DATASET. OUTPUT the train batches and val batches
    cmd: python src/features/tokenizer_language.py
    params:
    - model_name_zip
    - BUFFER_SIZE
    - BATCH_SIZE
    - MAX_TOKENS 
    deps: #Dependencies
    - src/data/load_dataset.py	
    outs:
    - train_batches
    - val_batches

  postional_encoding:
  # MAKE THE POSITIONAL EMBEDDINGS
    cmd: python src/features/positional_encoder.py
    params:
    - input_vocab_size
    - target_vocab_size
    - d_model 
    deps:
    - src/data/tokenized_transformer.py
    outs:
    - pt_emb
    - en_emb

  train_transformer:
  # INSTANTIATE ENCODER AND DECODER MODULES , THE TRANSFORMER ITSELF AND TRAINS IT
    cmd: python scr/models/train_transformers.py
    params:
    - num_layers
    - d_model
    - dff
    - num_attention_heads
    - dropout_rate
    - EPOCHS
    deps:
    - scr/models/encoder.py
    - scr/models/decoder.py
    outs:
    - model_trained.pb ?
    metrics:
      - training_metrics.json:
          cache: false
    plots:
      - training_metrics/scalars:
          cache: false

  predict_transformer: